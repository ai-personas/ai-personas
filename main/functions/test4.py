# -*- coding: utf-8 -*-
"""test5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GXRX4w2Ugp9fAnQyr3VoDExS0ZfdBHMz
"""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import hashlib
import math
import os.path
import random
import re
import sys
import tarfile

import numpy as np
from six.moves import urllib
from six.moves import xrange  # pylint: disable=redefined-builtin
import tensorflow as tf

from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio
from tensorflow.python.ops import io_ops
from tensorflow.python.platform import gfile
from tensorflow.python.util import compat

tf.enable_eager_execution()


# download data file
def maybe_download_and_extract_dataset(data_url, dest_directory):
    if not data_url:
        return
    if not os.path.exists(dest_directory):
        os.makedirs(dest_directory)
    filename = data_url.split('/')[-1]
    filepath = os.path.join(dest_directory, filename)
    if not os.path.exists(filepath):

        def _progress(count, block_size, total_size):
            sys.stdout.write(
                '\r>> Downloading %s %.1f%%' %
                (filename, float(count * block_size) / float(total_size) * 100.0))
            sys.stdout.flush()

        try:
            filepath, _ = urllib.request.urlretrieve(data_url, filepath, _progress)
        except:
            tf.logging.error('Failed to download URL: %s to folder: %s', data_url,
                             filepath)
            tf.logging.error('Please make sure you have enough free space and'
                             ' an internet connection')
            raise
        print()
        statinfo = os.stat(filepath)
        tf.logging.info('Successfully downloaded %s (%d bytes)', filename,
                        statinfo.st_size)
        tarfile.open(filepath, 'r:gz').extractall(dest_directory)


# download google speech file
data_dir = '/tmp/google/speech'
maybe_download_and_extract_dataset('http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz', data_dir)

label_file = []
# Look through all the subfolders to find audio samples
search_path = os.path.join(data_dir, '*', '*.wav')
for wav_path in gfile.Glob(search_path):
    _, word = os.path.split(os.path.dirname(wav_path))
    word = word.lower()
    label_file.append({'label': word, 'file': wav_path})
print("label_file len", len(label_file))


def get_audio_output(wav_filename):
    wav_loader = io_ops.read_file(wav_filename)
    wav_decoder = contrib_audio.decode_wav(wav_loader, desired_channels=1)
    return wav_decoder

def write_audio_output(wav_output_filename, data, sample_rate):
    wav_encoder = contrib_audio.encode_wav(data, sample_rate)
    io_ops.write_file(wav_output_filename, wav_encoder)

sample = label_file[0]
data_tensor = get_audio_output(sample['file'])
print(data_tensor)
sample_count = 10000
audio_size = 16000
data = np.zeros((sample_count, audio_size))
labels = set()

for i in range(sample_count):
    labels.add(label_file[i]['label'])

unique_label_index = {e: i for e, i in zip(labels, range(0, len(labels)))}
print(unique_label_index)

audio_data_size = 10240

def get_data(start, end):
    count = end-start
    training_inputs = np.zeros((count, 10))
    training_outputs = np.zeros((count, audio_data_size))
    for i in range(count):
        label_index = unique_label_index[label_file[i]['label']]
        label_one_hot = tf.one_hot(indices=label_index, depth=10, dtype=tf.float32)

        audio_file = label_file[i]['file']
        data_tensor = get_audio_output(audio_file)
        audio_data = data_tensor.audio.numpy().flatten()
        audio_data = np.resize(audio_data, 10240)

        training_inputs[i, :] = label_one_hot
        training_outputs[i, :] = audio_data
    return (training_inputs, training_outputs)


class Model(tf.keras.Model):
    def __init__(self):
        super(Model, self).__init__()
        self.dense1 = tf.keras.layers.Dense(10, input_shape=(10,), activation='relu')
        self.dense2 = tf.keras.layers.Dense(1000, input_shape=(1000,), activation='relu')
        self.dropout1 = tf.keras.layers.Dropout(0.5)
        self.dense3 = tf.keras.layers.Dense(2000, input_shape=(2000,), activation='relu')
        self.dropout2 = tf.keras.layers.Dropout(0.5)
        self.dense4 = tf.keras.layers.Dense(5000, input_shape=(5000,), activation='relu')
        self.dense5 = tf.keras.layers.Dense(audio_data_size, input_shape=(audio_data_size,), activation='relu')

    def call(self, inputs):
        x = self.dense1(inputs)
        x = self.dense2(x)
        x = self.dropout1(x)
        x = self.dense3(x)
        x = self.dropout2(x)
        x = self.dense4(x)
        x = self.dense5(x)
        return x

model = Model()

loss_history = []
batch_size = 100

# for i in range(sample_count):
#     label_index = unique_label_index[label_file[i]['label']]
#     label_one_hot = tf.one_hot(indices=label_index, depth=10, dtype=tf.float32)
#
#     audio_file = label_file[i]['file']
#     data_tensor = get_audio_output(audio_file)
#     audio_data = data_tensor.audio.numpy().flatten()
#     audio_data = np.resize(audio_data, 10240)
#
#     training_inputs[i, :] = label_one_hot
#     training_outputs[i, :] = audio_data

(x_train, y_train) = get_data(0, 5000)
(x_test, y_test) = get_data(5000, 10000)

model.compile(optimizer=tf.train.AdamOptimizer(),
              loss='cosine_proximity')

model.fit(x_train, y_train,
          epochs=100,
          validation_data=(x_test, y_test),
          batch_size=1024,
          verbose=2)

# loss_history = []
# optimizer = tf.train.AdamOptimizer()
# batch_size = 100
# training_inputs = np.zeros((batch_size, 10))
# training_outputs = np.zeros((batch_size, audio_data_size))
#
# for i in range(sample_count):
#     label_index = unique_label_index[label_file[i]['label']]
#     label_one_hot = tf.one_hot(indices=label_index, depth=10, dtype=tf.float32)
#
#     audio_file = label_file[i]['file']
#     data_tensor = get_audio_output(audio_file)
#     audio_data = data_tensor.audio.numpy().flatten()
#     audio_data = np.resize(audio_data, 10240)
#
#     if i % batch_size == 0:
#         with tf.GradientTape() as tape:
#             output_audio = model.call(training_inputs)
#             loss_value = tf.losses.log_loss(training_outputs, output_audio)
#         loss_history.append(loss_value.numpy())
#         grads = tape.gradient(loss_value, model.trainable_variables)
#         optimizer.apply_gradients(zip(grads, model.trainable_variables),
#                                   global_step=tf.train.get_or_create_global_step())
#         training_inputs = np.zeros((batch_size, 10))
#         training_outputs = np.zeros((batch_size, audio_data_size))
#     else:
#         training_inputs[i % batch_size, :] = label_one_hot
#         training_outputs[i % batch_size, :] = audio_data
#

# import matplotlib.pyplot as plt
#
# plt.plot(loss_history)
# plt.xlabel('Sample #')
# plt.ylabel('Loss [entropy]')
# plt.show()


# run the model
training_inputs = np.zeros((1, 10))
training_outputs = np.zeros((1, audio_data_size))

for i in range(10):
    label_index = unique_label_index[label_file[i]['label']]
    label_one_hot = tf.one_hot(indices=label_index, depth=10, dtype=tf.float32)
    training_inputs[0,:] = label_one_hot
    output_audio = model.call(training_inputs)
    output_audio = tf.reshape(output_audio, (10240,1))
    output_audio = tf.dtypes.cast(output_audio, dtype=tf.float32)
    print(output_audio)
    write_audio_output('/tmp/tst/'+label_file[i]['label']+str(i)+'.wav', output_audio.numpy(), 16000)





